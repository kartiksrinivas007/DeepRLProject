============================================================
start time: 25-12-09-14-53-46
============================================================
dataset size: 1327
returns max : 3908.8544921875
returns mean: 2817.7890625
returns std : 877.09326171875
returns min : 1350.3359375
Using Minari eval environment: Hopper-v5
Warning: could not load pretrained model: Error(s) in loading state_dict for ReinFormer:
	Unexpected key(s) in state_dict: "transformer.4.attention.mask", "transformer.4.attention.q_net.weight", "transformer.4.attention.q_net.bias", "transformer.4.attention.k_net.weight", "transformer.4.attention.k_net.bias", "transformer.4.attention.v_net.weight", "transformer.4.attention.v_net.bias", "transformer.4.attention.proj_net.weight", "transformer.4.attention.proj_net.bias", "transformer.4.mlp.0.weight", "transformer.4.mlp.0.bias", "transformer.4.mlp.2.weight", "transformer.4.mlp.2.bias", "transformer.4.ln1.weight", "transformer.4.ln1.bias", "transformer.4.ln2.weight", "transformer.4.ln2.bias", "transformer.5.attention.mask", "transformer.5.attention.q_net.weight", "transformer.5.attention.q_net.bias", "transformer.5.attention.k_net.weight", "transformer.5.attention.k_net.bias", "transformer.5.attention.v_net.weight", "transformer.5.attention.v_net.bias", "transformer.5.attention.proj_net.weight", "transformer.5.attention.proj_net.bias", "transformer.5.mlp.0.weight", "transformer.5.mlp.0.bias", "transformer.5.mlp.2.weight", "transformer.5.mlp.2.bias", "transformer.5.ln1.weight", "transformer.5.ln1.bias", "transformer.5.ln2.weight", "transformer.5.ln2.bias". 
	size mismatch for transformer.0.attention.mask: copying a param with shape torch.Size([1, 1, 60, 60]) from checkpoint, the shape in current model is torch.Size([1, 1, 15, 15]).
	size mismatch for transformer.1.attention.mask: copying a param with shape torch.Size([1, 1, 60, 60]) from checkpoint, the shape in current model is torch.Size([1, 1, 15, 15]).
	size mismatch for transformer.2.attention.mask: copying a param with shape torch.Size([1, 1, 60, 60]) from checkpoint, the shape in current model is torch.Size([1, 1, 15, 15]).
	size mismatch for transformer.3.attention.mask: copying a param with shape torch.Size([1, 1, 60, 60]) from checkpoint, the shape in current model is torch.Size([1, 1, 15, 15]).
